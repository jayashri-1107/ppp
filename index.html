<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Programs</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            overflow-x: auto;
        }
        h2 {
            color: #333;
        }
    </style>
</head>
<body>
    <h1>Machine Learning Lab Programs</h1>

    <h2>1. Python Program to Find Mean, Median, and Mode</h2>
    <pre>
# Mean
import numpy
speed = [99,86,87,88,111,86,103,87,94,78,77,85,86]
x = numpy.mean(speed)
print(x)

# Median
x = numpy.median(speed)
print(x)

# Mode
from scipy import stats
x = stats.mode(speed)
print(x)
    </pre>

    <h2>2. Python Program for Typical Normal Data Distribution</h2>
    <pre>
from numpy import random
import matplotlib.pyplot as plt
import seaborn as sns
sns.distplot(random.normal(size=1000), hist=False)
plt.show()
    </pre>

    <h2>3. Python Program to Draw Scatter Plot of Linear Regression</h2>
    <pre>
import numpy as np
import matplotlib.pyplot as plt
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 3, 5, 7, 11])
plt.scatter(x, y, color='blue', label='Data points')
m, b = np.polyfit(x, y, 1)
plt.plot(x, m*x + b, color='red', label='Regression line')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.title('Scatter Plot with Linear Regression Line')
plt.legend()
plt.show()
    </pre>

    <h2>4. Python Program to Draw the Line of Linear Regression</h2>
    <pre>
import matplotlib.pyplot as plt
from scipy import stats
x = [5,7,8,7,2,17,2,9,4,11,12,9,6]
y = [99,86,87,88,111,86,103,87,94,78,77,85,86]
slope, intercept, r, p, std_err = stats.linregress(x, y)
def myfunc(x):
  return slope * x + intercept
mymodel = list(map(myfunc, x))
plt.scatter(x, y)
plt.plot(x, mymodel)
plt.show()
    </pre>

    <h2>5. Python Program to Predict Speed of a 5-Year-Old Car</h2>
    <pre>
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
ages = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
speeds = np.array([120, 115, 110, 105, 100, 95, 90, 85, 80, 75])
slope, intercept, r_value, p_value, std_err = stats.linregress(ages, speeds)
def predict_speed(age):
    return slope * age + intercept
predicted_speed = predict_speed(5)
print(f"The predicted speed of a 5-year-old car is {predicted_speed:.2f} km/h")
plt.scatter(ages, speeds, color='blue', label='Actual data')
plt.plot(ages, predict_speed(ages), color='red', label='Regression line')
plt.xlabel('Age of car (years)')
plt.ylabel('Speed of car (km/h)')
plt.legend()
plt.show()
    </pre>

    <h2>6. Python Program to Print Coefficient Values of Regression Object</h2>
    <pre>
import numpy as np
from sklearn.linear_model import LinearRegression
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3
model = LinearRegression().fit(X, y)
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)
    </pre>

    <h2>7. Python Program for 2D Binary Classification using make_circles()</h2>
    <pre>
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_circles
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
X, y = make_circles(n_samples=300, factor=0.5, noise=0.1, random_state=42)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
svm = SVC(kernel='rbf', C=1.0, gamma='auto')
svm.fit(X_scaled, y)
def plot_decision_boundary(model, X, y):
    h = .02
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.8)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('SVM with RBF Kernel Decision Boundary')
    plt.show()
plot_decision_boundary(svm, X_scaled, y)
    </pre>

    <h2>8. Python Program to Display a Plot</h2>
    <pre>
import matplotlib.pyplot as plt
x = [1, 2, 3, 4]
y = [2, 4, 1, 3]
plt.plot(x, y)
plt.xlabel('x - axis')
plt.ylabel('y - axis')
plt.title('Simple Plot')
plt.show()
    </pre>

    <h2>9. Python Program for Clustering Using make_blobs()</h2>
    <pre>
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
X, y = make_blobs(n_samples=300, centers=4, n_features=2, cluster_std=1.0, random_state=42)
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(X)
y_kmeans = kmeans.predict(X)
plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('K-Means Clustering')
plt.show()
    </pre>

    <h2>10. Python Program for Multi-label Classification Using make_multilabel_classification()</h2>
    <pre>
from sklearn.datasets import make_multilabel_classification
import matplotlib.pyplot as plt
X, y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=5, n_labels=3, random_state=42)
print("Features shape:", X.shape)
print("Labels shape:", y.shape)
plt.scatter(X[:, 0], X[:, 1], marker='o', c=y[:, 0], edgecolor='k')
plt.title("Random Multi-label Classification Data")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()
    </pre>

    <h2>11. Python Program to Implement KNN Algorithm</h2>
    <pre>
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')
    </pre>

    <h2>12. Python Program for One-Hot Encoding from CSV File</h2>
    <pre>
import pandas as pd
df = pd.read_csv('Candy_Sales.csv')
categorical_columns = df.select_dtypes(include=['object']).columns
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)
print(df_encoded.head())
    </pre>
</body>
</html>
